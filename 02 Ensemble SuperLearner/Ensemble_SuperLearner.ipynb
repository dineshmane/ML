{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: The Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "ticks = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import data_viz_target\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import ipdb\n",
    "import copy\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Super Learner Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Super Learner* is a heterogeneous stacked ensemble classifier. This is a classification model that uses a set of base classifiers of different types, the outputs of which are then combined in another classifier at the stacked layer. The Super Learner was described in [(van der Laan et al, 2007)](https://pdfs.semanticscholar.org/19e9/c732082706f39d2ba12845851309714db135.pdf) but the stacked ensemble idea has been around for a long time. \n",
    "\n",
    "Figure 1 shows a flow diagram of the Super Learner process (this is from (van der Laan et al, 2007) and the process is also described in the COMP47590 lecture \"[COMP47590 2017-2018 L04 Supervised Learning Ensembles 3](https://www.dropbox.com/s/1ksx94nxtuyn4l8/COMP47590%202017-2018%20L04%20Supervised%20Learning%20Ensembles%203.pdf?raw=1)\"). The base classifiers are trained and their outputs are combined along with the training dataset labels into a training set for the stack layer classifier. To avoid overfitting the generation of the stacked layer training set uses a k-fold cross validation process (described as V-fold in Figure 1). To further add variety to the base estimators a bootstrapping selection (as is used in the bagging ensemble approach).\n",
    " \n",
    "![Super Learner Process Flow](SuperLearnerProcessFlow.png \"Logo Title Text 1\")\n",
    "Figure 1: A flow diagram for the Super Learner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SuperLearnerClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class SuperLearnerClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v_fold - number of folds used to generate input for stack layer default is 5\n",
    "    baseClfList - list which contains models used for base estimators\n",
    "    multiplyBaseClf - multiplication factor for base estimators to genearate ensemble default is one\n",
    "    stackLayerClf - type of model used for stack layer default is Tree\n",
    "    use_base_prob - use of Probablity outputs of base classifier when it is true\n",
    "    add_ip_features_stackLayer = False\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    No attributes\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Super Learner algorithm which takes fixed set of 6 base models from scikit-learn \n",
    "    (e.g. decision trees, logistic regression, or neural networks models). \n",
    "    It is ensemble approach with heterogeneous models.\n",
    "    Reasonable default hyper-parameters for these base estimators are alreday set.\n",
    "    Stacked layer takes the label outputs from the base estimators.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "\n",
    "    \"\"\"\n",
    "    v_fold = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, v_fold=5 ,baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], multiplyBaseClf=1,\\\n",
    "                 stackLayerClf = tree.DecisionTreeClassifier(criterion=\"entropy\") , \\\n",
    "                 use_base_prob=False, add_ip_features_stackLayer = False):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        v_fold - number of folds used to generate input for stack layer default is 5\n",
    "        baseClfList - list which contains models used for base estimators\n",
    "        multiplyBaseClf - multiplication factor for base estimators to genearate ensemble default is one\n",
    "        stackLayerClf - type of model used for stack layer default is Tree\n",
    "        use_base_prob - use of Probablity outputs of base classifier when it is true\n",
    "        add_ip_features_stackLayer = False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\" \n",
    "        \n",
    "        self.v_fold = v_fold\n",
    "        r = []\n",
    "        for i in range(multiplyBaseClf):\n",
    "            r = r + baseClfList\n",
    "        baseClfList = r\n",
    "        self.baseClfList = baseClfList\n",
    "        self.multiplyBaseClf = multiplyBaseClf\n",
    "        self.stackLayerClf = stackLayerClf\n",
    "        self.add_ip_features_stackLayer = add_ip_features_stackLayer\n",
    "        self.use_base_prob = use_base_prob\n",
    "\n",
    "        \n",
    "    def re_train_base_models(self, X, Y, baseClfList):\n",
    "        \"\"\" training base classifier with whole dataset again .\n",
    "        Parameters\n",
    "        ----------\n",
    "        X - array-like, shape = [n_samples, n_features]\n",
    "            Input features dataframe\n",
    "        Y - array-like, shape = [n_samples, 1]\n",
    "            Target labels\n",
    "        baseClfList - List of base estimators\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\" \n",
    "        for base in baseClfList:\n",
    "            if base == \"tree\":\n",
    "                self.tree_model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "                self.tree_model.fit(X,Y)\n",
    "            elif base == \"logit\":\n",
    "                self.logit_model = linear_model.LogisticRegression(C=0.6, max_iter=1000, multi_class=\"ovr\", solver=\"liblinear\")\n",
    "                self.logit_model.fit(X,Y)\n",
    "            elif base == \"random_forest\":\n",
    "                self.random_forest_model = ensemble.RandomForestClassifier(n_estimators=150, \\\n",
    "                                               max_features = 10,\\\n",
    "                                               min_samples_split=20)\n",
    "                self.random_forest_model.fit(X,Y)  \n",
    "            elif base == \"tree_bagging\":\n",
    "                self.tree_bagging_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", \\\n",
    "                                                                                        min_samples_leaf = 50), \\\n",
    "                                                                                        n_estimators=10)\n",
    "                self.tree_bagging_model.fit(X,Y)  \n",
    "            elif base == \"tree_adaboost\":\n",
    "                self.tree_adaboost_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\",\\\n",
    "                                                                                        min_samples_leaf = 200), \\\n",
    "                                                                                        n_estimators=10)\n",
    "                self.tree_adaboost_model.fit(X,Y)  \n",
    "            elif base == \"knn\":\n",
    "                self.knn_model = neighbors.KNeighborsClassifier(n_neighbors=6)\n",
    "                self.knn_model.fit(X,Y)  \n",
    "            elif base == \"nn\":\n",
    "                self.nn_model = neural_network.MLPClassifier(hidden_layer_sizes=(180,120,80,40))\n",
    "                self.nn_model.fit(X,Y)  \n",
    "            else:\n",
    "                print(\"No classifier found in implementation -> \" , base)\n",
    "            #print(\"Base classifiers re-training successful\")\n",
    "            \n",
    "    \n",
    "    def train_base_models(self, X_train, X_valid, y_train, y_valid, baseClfList):\n",
    "        \"\"\" training base classifier to generate input for stack classifier by using holdout dataset .\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train - array-like, shape = [n_samples_train, n_features]\n",
    "                  Input features of training set \n",
    "        X_valid - array-like, shape = [n_samples_valid, n_features]\n",
    "                  Input features of validation set \n",
    "        y_train - array-like, shape = [n_samples_train, 1]\n",
    "                  Target labels of training set \n",
    "        y_valid - array-like, shape = [n_samples_valid, 1]\n",
    "                  Target labels of validation set \n",
    "        baseClfList - List of base estimators\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\" \n",
    "        count = 0 \n",
    "        for base in baseClfList:\n",
    "            if base == \"tree\":\n",
    "                model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "            elif base == \"logit\":\n",
    "                model = linear_model.LogisticRegression(C=0.6, max_iter=1000, multi_class=\"ovr\", solver=\"liblinear\")\n",
    "            elif base == \"random_forest\":\n",
    "                model = ensemble.RandomForestClassifier(n_estimators=150, \\\n",
    "                                                           max_features = 10,\\\n",
    "                                                           min_samples_split=20)\n",
    "            elif base == \"tree_bagging\":\n",
    "                model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\",\\\n",
    "                                                        min_samples_leaf = 50), \\\n",
    "                                                        n_estimators=10)\n",
    "            elif base == \"tree_adaboost\":\n",
    "                model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\",\\\n",
    "                                                        min_samples_leaf = 200), \\\n",
    "                                                        n_estimators=10)\n",
    "            elif base == \"knn\":\n",
    "                model = neighbors.KNeighborsClassifier(n_neighbors=6)\n",
    "            elif base == \"nn\":\n",
    "                model = neural_network.MLPClassifier(hidden_layer_sizes=(180,120,80,40))\n",
    "            else:\n",
    "                print(\"No classifier found in implementation -> \" , base)\n",
    "                return\n",
    "            \n",
    "            model.fit(X_train,y_train)\n",
    "            y_pred = model.predict(X_valid)\n",
    "            \n",
    "            self.output_df[base] = y_pred\n",
    "            self.orig_output_df[base] = y_pred\n",
    "            #for predict_proba() method\n",
    "            dany = model.predict_proba(X_valid)\n",
    "            dany= pd.DataFrame(dany)\n",
    "            li = [ \"Mod_\"+ str(i) for i in range(1+count,11+count)]\n",
    "            count += 10 \n",
    "            dany.columns =(li)\n",
    "            \n",
    "            self.prob_output_df = pd.concat([self.prob_output_df, dany], axis=1) # 1200 * 21\n",
    "            self.orig_prob_output_df = pd.concat([self.orig_prob_output_df, dany], axis=1)\n",
    "\n",
    "       \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples,1] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"     \n",
    "        cv_fold = self.v_fold\n",
    "        self.clf_output_df = pd.DataFrame()                  \n",
    "        self.clf_orig_output_df = pd.DataFrame()\n",
    "        self.clf_prob_output_df = pd.DataFrame()\n",
    "        self.clf_orig_prob_output_df = pd.DataFrame()\n",
    "        for i in range(cv_fold):\n",
    "            self.output_df = pd.DataFrame()                #these are iniitlize here so that every thime these are initilze to null data frame\n",
    "            self.orig_output_df = pd.DataFrame()\n",
    "            \n",
    "            self.prob_output_df = pd.DataFrame()\n",
    "            self.orig_prob_output_df = pd.DataFrame()\n",
    "            global count \n",
    "            count = 0\n",
    "            \n",
    "            part = len(X) - int(len(X) / cv_fold)\n",
    "            X_head = X.iloc[:part][:]\n",
    "            X_tail = X.iloc[part:][:]\n",
    "            X = pd.concat([X_tail, X_head])\n",
    "            Y_head = Y[:part]\n",
    "            Y_tail = Y[part:]\n",
    "            Y = np.append(Y_tail, Y_head)\n",
    "\n",
    "            X_train, X_valid, y_train, y_valid \\\n",
    "                = train_test_split(X, Y, random_state=0, \\\n",
    "                                                train_size = (1 - 1/ cv_fold))\n",
    "            \n",
    "#for normal predictions            \n",
    "            self.output_df = self.output_df.assign(label = y_valid)\n",
    "            self.orig_output_df = X_valid\n",
    "            self.orig_output_df = self.orig_output_df.assign(label = y_valid)\n",
    "#for the probablity predictions \n",
    "            self.prob_output_df[\"label\"] = y_valid\n",
    "            \n",
    "            self.orig_prob_output_df = X_valid\n",
    "            self.orig_prob_output_df = self.orig_prob_output_df.reset_index(drop=True)  #resettiing the index\n",
    "            self.orig_prob_output_df = self.orig_prob_output_df.assign(label = y_valid)\n",
    "    \n",
    "            self.train_base_models(X_train, X_valid, y_train, y_valid, self.baseClfList)\n",
    "\n",
    "            self.clf_output_df = pd.concat([self.clf_output_df, self.output_df])\n",
    "            self.clf_orig_output_df = pd.concat([self.clf_orig_output_df, self.orig_output_df])\n",
    "            \n",
    "            self.clf_prob_output_df = pd.concat([self.clf_prob_output_df, self.prob_output_df], axis=0)\n",
    "            self.clf_orig_prob_output_df = pd.concat([self.clf_orig_prob_output_df, self.orig_prob_output_df], axis=0)\n",
    "            \n",
    "        \n",
    "        #here we will train all base classifers with entire data\n",
    "        self.re_train_base_models(X, Y, self.baseClfList)\n",
    "        #now we will train our finalClassifier. \n",
    "        X_ = \"\"\n",
    "        Y_ = \"\"\n",
    "        my_stack_layer_clf = \"\"\n",
    "        \n",
    "        if self.add_ip_features_stackLayer == True :\n",
    "            X_ = self.clf_orig_output_df.loc[:, self.clf_orig_output_df.columns != \"label\"]\n",
    "            Y_ = self.clf_orig_output_df[\"label\"]\n",
    "        else:\n",
    "            X_ = self.clf_output_df.loc[:, self.clf_output_df.columns != \"label\"]\n",
    "            Y_ = self.clf_output_df[\"label\"]\n",
    "\n",
    "        clf_temp = copy.deepcopy(self.stackLayerClf)\n",
    "        clf_temp.fit(X_,Y_)\n",
    "        self.final_model = clf_temp\n",
    "                \n",
    "        if self.add_ip_features_stackLayer == True :\n",
    "            X_ = self.clf_orig_prob_output_df.loc[:, self.clf_orig_prob_output_df.columns != \"label\"]\n",
    "            Y_ = self.clf_orig_prob_output_df[\"label\"]\n",
    "        else:\n",
    "            X_ = self.clf_prob_output_df.loc[:, self.clf_prob_output_df.columns != \"label\"]\n",
    "            Y_ = self.clf_prob_output_df[\"label\"]\n",
    "\n",
    "        clf_temp = copy.deepcopy(self.stackLayerClf)\n",
    "        clf_temp.fit(X_,Y_)\n",
    "        self.final_prob_model = clf_temp\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        final_df = pd.DataFrame()\n",
    "        if self.use_base_prob == True:\n",
    "            if self.add_ip_features_stackLayer == True :\n",
    "                X_ = copy.deepcopy(X)\n",
    "                X_ = X_.reset_index(drop=True)\n",
    "                final_df = X_\n",
    "\n",
    "            for base in self.baseClfList:\n",
    "                if base == \"tree\":\n",
    "                    y_hat = self.tree_model.predict_proba(X)\n",
    "                elif base == \"logit\":\n",
    "                    y_hat = self.logit_model.predict_proba(X)\n",
    "                elif base == \"random_forest\":\n",
    "                    y_hat = self.random_forest_model.predict_proba(X)\n",
    "                elif base == \"tree_bagging\":\n",
    "                    y_hat = self.tree_bagging_model.predict_proba(X)\n",
    "                elif base == \"tree_adaboost\":\n",
    "                    y_hat = self.tree_adaboost_model.predict_proba(X)\n",
    "                elif base == \"knn\":\n",
    "                    y_hat = self.knn_model.predict_proba(X)\n",
    "                elif base == \"nn\":\n",
    "                    y_hat = self.nn_model.predict_proba(X)\n",
    "                else:\n",
    "                    print(\"No class implementation for --> \" , base)\n",
    "                \n",
    "                y_hat = pd.DataFrame(y_hat)\n",
    "                li = [ \"Mod_\"+ str(i) for i in range(1+count,11+count)]\n",
    "                count += 10 \n",
    "                y_hat.columns = (li)\n",
    "                final_df = pd.concat([final_df, y_hat], axis=1)\n",
    "            \n",
    "            y_pred = self.final_prob_model.predict(final_df)\n",
    "\n",
    "        else:\n",
    "            if self.add_ip_features_stackLayer == True :\n",
    "                final_df = copy.deepcopy(X)\n",
    "            for base in self.baseClfList:\n",
    "                if base == \"tree\":\n",
    "                    y_hat = self.tree_model.predict(X)\n",
    "                elif base == \"logit\":\n",
    "                    y_hat = self.logit_model.predict(X)\n",
    "                elif base == \"random_forest\":\n",
    "                    y_hat = self.random_forest_model.predict(X)\n",
    "                elif base == \"tree_bagging\":\n",
    "                    y_hat = self.tree_bagging_model.predict(X)\n",
    "                elif base == \"tree_adaboost\":\n",
    "                    y_hat = self.tree_adaboost_model.predict(X)\n",
    "                elif base == \"knn\":\n",
    "                    y_hat = self.knn_model.predict(X)\n",
    "                elif base == \"nn\":\n",
    "                    y_hat = self.nn_model.predict(X)\n",
    "                else:\n",
    "                    print(\"No class implementation for --> \" , base)\n",
    "                \n",
    "                final_df[base] = y_hat\n",
    "            \n",
    "            y_pred = self.final_model.predict(final_df)\n",
    "        return y_pred\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        final_df = pd.DataFrame()\n",
    "        \n",
    "        if self.use_base_prob == True:\n",
    "            if self.add_ip_features_stackLayer == True :\n",
    "                    X_ = copy.deepcopy(X)\n",
    "                    X_ = X_.reset_index(drop=True)\n",
    "                    final_df = X_\n",
    "\n",
    "            for base in self.baseClfList:\n",
    "                if base == \"tree\":\n",
    "                    y_hat = self.tree_model.predict_proba(X)\n",
    "                elif base == \"logit\":\n",
    "                    y_hat = self.logit_model.predict_proba(X)\n",
    "                elif base == \"random_forest\":\n",
    "                    y_hat = self.random_forest_model.predict_proba(X)\n",
    "                elif base == \"tree_bagging\":\n",
    "                    y_hat = self.tree_bagging_model.predict_proba(X)\n",
    "                elif base == \"tree_adaboost\":\n",
    "                    y_hat = self.tree_adaboost_model.predict_proba(X)\n",
    "                elif base == \"knn\":\n",
    "                    y_hat = self.knn_model.predict_proba(X)\n",
    "                elif base == \"nn\":\n",
    "                    y_hat = self.nn_model.predict_proba(X)\n",
    "                else:\n",
    "                    print(\"No class implementation for --> \" , base)\n",
    "                \n",
    "                y_hat = pd.DataFrame(y_hat)\n",
    "                li = [ \"Mod_\"+ str(i) for i in range(1+count,11+count)]\n",
    "                count += 10 \n",
    "                y_hat.columns = (li)\n",
    "                final_df = pd.concat([final_df, y_hat], axis=1)\n",
    "\n",
    "            y_pred = self.final_prob_model.predict_proba(final_df)\n",
    "            \n",
    "        else:\n",
    "            if self.add_ip_features_stackLayer == True :\n",
    "                final_df = copy.deepcopy(X)\n",
    "            for base in self.baseClfList:\n",
    "                if base == \"tree\":\n",
    "                    y_hat = self.tree_model.predict(X)\n",
    "                elif base == \"logit\":\n",
    "                    y_hat = self.logit_model.predict(X)\n",
    "                elif base == \"random_forest\":\n",
    "                    y_hat = self.random_forest_model.predict(X)\n",
    "                elif base == \"tree_bagging\":\n",
    "                    y_hat = self.tree_bagging_model.predict(X)\n",
    "                elif base == \"tree_adaboost\":\n",
    "                    y_hat = self.tree_adaboost_model.predict(X)\n",
    "                elif base == \"knn\":\n",
    "                    y_hat = self.knn_model.predict(X)\n",
    "                elif base == \"nn\":\n",
    "                    y_hat = self.nn_model.predict(X)\n",
    "                else:\n",
    "                    print(\"No class implementation for --> \" , base)\n",
    "                \n",
    "                final_df[base] = y_hat\n",
    "            \n",
    "            y_pred = self.final_model.predict_proba(final_df)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 1   #LM change it to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> This below code will give us uniform distributed examples from 60000 examples to 6000 examples. This needs to be run only once so I've commented out. This stratified 6000 examples will be used for training purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "df.head()\n",
    "df = df.sample(frac=1)\n",
    "df0 = df[df.loc[:][\"label\"] == 0].head(600)\n",
    "df1 = df[df.loc[:][\"label\"] == 1].head(600)\n",
    "df2 = df[df.loc[:][\"label\"] == 2].head(600)\n",
    "df3 = df[df.loc[:][\"label\"] == 3].head(600)\n",
    "df4 = df[df.loc[:][\"label\"] == 4].head(600)\n",
    "df5 = df[df.loc[:][\"label\"] == 5].head(600)\n",
    "df6 = df[df.loc[:][\"label\"] == 6].head(600)\n",
    "df7 = df[df.loc[:][\"label\"] == 7].head(600)\n",
    "df8 = df[df.loc[:][\"label\"] == 8].head(600)\n",
    "df9 = df[df.loc[:][\"label\"] == 9].head(600)\n",
    "\n",
    "clubbedDf = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8, df9])\n",
    "\n",
    "clubbedDf.to_csv(\"fashion-mnist_train_small.csv\", index=False)\n",
    "\n",
    "dataset = pd.read_csv('fashion-mnist_train_small.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #LM\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: </b> This below code will uniformly distributed 10000 examples from test.csv dataset. This set is used as hold out dataset in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "#test_dataset = test_dataset.sample(frac = 0.1)   #LM remove this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check the label count\n",
      "7    600\n",
      "3    600\n",
      "6    600\n",
      "2    600\n",
      "9    600\n",
      "5    600\n",
      "1    600\n",
      "8    600\n",
      "4    600\n",
      "0    600\n",
      "Name: label, dtype: int64\n",
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"check the label count\")\n",
    "print(dataset[\"label\"].value_counts())\n",
    "\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data pre-processing and manipulation as required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> For few tasks I have used X_train dataset for training purpose and X_valid dataset for evaluation purpose. Due to lack of computational power. X will have 6000 examples, X_test will have 10000 examles, X_cross will have 600 examples thoughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the training dataset (train.csv file)\n",
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])\n",
    "X = X/255                      # for normalizing the inputs\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, random_state=0, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalizing the test dataset (test.csv)\n",
    "X_test = test_dataset[test_dataset.columns[1:]]\n",
    "Y_test = np.array(test_dataset[\"label\"])\n",
    "X_test = X_test/255           # for normalizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using 1/10th fraction of train.csv dataset for cross validation purpose.\n",
    "cross_dataset = dataset.sample(frac = 0.1)\n",
    "X_cross = cross_dataset[cross_dataset.columns[1:]]\n",
    "Y_cross = np.array(cross_dataset[\"label\"])\n",
    "X_cross = X_cross/255                      # for normalizing the inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate a Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Super Learner Classifier using the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(add_ip_features_stackLayer=False,\n",
       "            baseClfList=['tree', 'logit', 'tree_adaboost'],\n",
       "            multiplyBaseClf=1,\n",
       "            stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            use_base_prob=False, v_fold=5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su =  SuperLearnerClassifier()\n",
    "su.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: </b> Here we can use three types of evaluation methods for our evaluation task throughout the notebook  \n",
    "1. simple one-way hold out the strategy \n",
    "      - Split the train.csv dataset in train/test set as 80/20 and use it for evaluation. But here the examples may not be  uniformly distributed\n",
    "      - Use train.csv dataset (6000 uniformly distributed examples) to train and test.csv dataset (10000 uniformly distributed examples) for evaluation. As our both dataset have same uniform distribution so it is sensible to use Accuracy / F1 measure as performance evaluation metric.\n",
    "2. Three-way holdout strategy: Split train.csv dataset into train/valid dataset and use test.csv dataset as the test dataset.\n",
    "3. Cross fold strategy: Use 10 fold cross validation on the train.csv (Due to lack of computational power I'm using 600 examples for cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predict method --> 0.8091666666666667\n",
      "Accuracy for predict_proba method --> 0.8091666666666667\n"
     ]
    }
   ],
   "source": [
    "# Here we are using 20% of data from train.csv to evaluate the model.\n",
    "y_hat = su.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_hat) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy for predict method -->\" ,accuracy)\n",
    "\n",
    "y_hat = su.predict_proba(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid,y_hat.argmax(axis=1))\n",
    "print(\"Accuracy for predict_proba method -->\" ,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> In below cell, I've trained the SuperLearner classifier with entire training dataset 6000 examples. And hold out set (test.csv) is used to evaluate the model. Approch one which was discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:--> 0.8286\n"
     ]
    }
   ],
   "source": [
    "#training the superlearner model with train.csv dataset\n",
    "su =  SuperLearnerClassifier()\n",
    "su.fit(X, Y)\n",
    "\n",
    "#evaluting with test.csv dataset (hold out dataset)\n",
    "y_hat = su.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy:-->\" ,accuracy)\n",
    "\n",
    "#y_hat = su.predict_proba(X_test)\n",
    "#accuracy = metrics.accuracy_score(Y_test,y_hat.argmax(axis=1))\n",
    "#print(\"Accuracy for predict_proba method -->\" ,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Experiment (Task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a 10-fold cross validation experiment to evaluate the performance of the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: </b> As our training dataset (6000 examples) is equally distributed amongst target label i.e. 600 examples for each target label. Also, our testing dataset (10000 examples) is equally distributed amongst target labels i.e. 1000 examples for each target label. As train and test dataset have same distribution it would be sensible to use Accuracy or F1 measure to evaluate the performance of Super learner model. If data is not equally distributed then we would have thought of Precision/ recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lack of computational power I am using 1/10 fraction of train.csv dataset for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : [0.734375   0.66129032 0.79032258 0.64516129 0.81967213 0.76666667\n",
      " 0.68965517 0.68965517 0.70175439 0.76785714]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(su, X_cross, Y_cross, cv=10)  \n",
    "print(\"Accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 measure : [0.75674853 0.66222833 0.75525641 0.64783911 0.76459873 0.76459996\n",
      " 0.63080469 0.64985015 0.75190115 0.76589522]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(su, X_cross, Y_cross, cv=10 , scoring='f1_macro')  \n",
    "print(\"F1 measure :\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_score were calculated on fewer examples so might have small scores compare to simple holdout strategy evaluation experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:--> 0.8286\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on test.csv dataset 10000 examples\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat)\n",
    "print(\"Accuracy:-->\" ,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:--> 0.827256298780822\n"
     ]
    }
   ],
   "source": [
    "#F1 measure on test.csv dataset 10000 examples\n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"F1 Score:-->\" ,f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Different Stack Layer Approaches (Task 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the ensemble when a label based stack layer training set and a probability based stack layer training set is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: </b> Here I am using 80% of train.csv to fit the super learner and 20% to evaluate the performance. If data distribution is disturbed largely after split then accuracy/f1 measure might not be good evaluation metric. But assuming very small disturbance in a data distribution, accuracy/F1 measure will be a fine metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label based + Tree for stack layer --> 0.8075\n",
      "probablity based + Tree for stack layer --> 0.7558333333333334\n",
      "Label based + Logit for stack layer --> 0.8091666666666667\n",
      "probablity based + logit for stack layer --> 0.7566666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_valid, y_train, y_valid\n",
    "# defining Tree and logit model for stack layer\n",
    "clf_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf_logit = linear_model.LogisticRegression()\n",
    "\n",
    "#label based super learner + Tree for stack layer\n",
    "su1 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=False)  \n",
    "su1.fit(X_train, y_train)\n",
    "\n",
    "#probablity based super learner + Tree for stack layer\n",
    "su2 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=True)\n",
    "su2.fit(X_train, y_train)\n",
    "\n",
    "#label based super learner + Logit for stack layer\n",
    "su3 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=False)\n",
    "su3.fit(X_train, y_train)\n",
    "\n",
    "#probablity based super learner + Logit for stack layer\n",
    "su4 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=True)\n",
    "su4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_hat = su1.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_hat) \n",
    "print(\"Label based + Tree for stack layer -->\" , accuracy)\n",
    "y_hat = su2.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_hat) \n",
    "print(\"probablity based + Tree for stack layer -->\" , accuracy)\n",
    "y_hat = su3.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_hat) \n",
    "print(\"Label based + Logit for stack layer -->\" , accuracy)\n",
    "y_hat = su4.predict(X_valid)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_hat) \n",
    "print(\"probablity based + logit for stack layer -->\" , accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> Here I am using train.csv dataset (6000 examples) for training purpose and test.csv dataset (10000 examples) as a holdout set for evaluation purpose. Basically, this should give higher accuracy than the previous cell as the model is trained on more data and also as data distribution is uniform among train and test data, accuracy and F1 measure will be a perfect choice of evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label based      + Tree for stack layer    --> Accuracy is :  0.83  F1 score is :  0.83\n",
      "probablity based + Tree for stack layer    --> Accuracy is :  0.78  F1 score is :  0.78\n",
      "Label based      + Logit for stack layer   --> Accuracy is :  0.83  F1 score is :  0.83\n",
      "probablity based + logit for stack layer   --> Accuracy is :  0.78  F1 score is :  0.77\n"
     ]
    }
   ],
   "source": [
    "# 6000 examples for training and hold out set of test.csv for evalution\n",
    "\n",
    "# defining Tree and logit model for stack layer\n",
    "clf_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf_logit = linear_model.LogisticRegression()\n",
    "\n",
    "#label based super learner + Tree for stack layer\n",
    "su1 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=False)  \n",
    "su1.fit(X, Y)\n",
    "\n",
    "#probablity based super learner + Tree for stack layer\n",
    "su2 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=True)\n",
    "su2.fit(X, Y)\n",
    "\n",
    "#label based super learner + Logit for stack layer\n",
    "su3 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=False)\n",
    "su3.fit(X, Y)\n",
    "\n",
    "#probablity based super learner + Logit for stack layer\n",
    "su4 =  SuperLearnerClassifier(v_fold=5, baseClfList=[\"tree\", \"logit\", \"tree_adaboost\"], stackLayerClf=clf_tree, use_base_prob=True)\n",
    "su4.fit(X, Y)\n",
    "\n",
    "\n",
    "y_hat = su1.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"Label based      + Tree for stack layer    --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))\n",
    "y_hat = su2.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"probablity based + Tree for stack layer    --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))\n",
    "y_hat = su3.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"Label based      + Logit for stack layer   --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))\n",
    "y_hat = su4.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"probablity based + logit for stack layer   --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Through SuperLearnerClassifier Architectures & Parameters (Task 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a grid search experiment to detemrine the optimal architecture and hyper-parameter values for the SuperLearnClasssifier for the MNIST Fashion classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> If we keep hyper-parameter multiplyBaseClf = 5 and list of 100 base estimator, then our Super Learner model will have total 500 (5 * 100) models. Cool! .Due to lack of computational resources, I am restricting the base classifiers to 2 sets of 3 estimators each only and keeping multiplication factor to 2. This will create two super learner models with 6 base classifier in each super learner. I am using a train.csv 6000 examples for GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 1.7min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 1.5min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 1.6min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 1.7min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 1.7min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 1.9min\n",
      "[CV] baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree', 'logit', 'tree_bagging'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 2.9min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 3.9min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 3.9min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=True, v_fold=5, total= 1.9min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 2.0min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 2.0min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), use_base_prob=False, v_fold=5, total= 2.1min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 2.1min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 2.2min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=True, v_fold=5, total= 2.1min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 2.1min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 2.2min\n",
      "[CV] baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5 \n",
      "[CV]  baseClfList=('tree_adaboost', 'knn', 'random_forest'), multiplyBaseClf=2, stackLayerClf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), use_base_prob=False, v_fold=5, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 56.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SuperLearnerClassifier(add_ip_features_stackLayer=False,\n",
       "            baseClfList=['tree', 'logit', 'tree_adaboost'],\n",
       "            multiplyBaseClf=1,\n",
       "            stackLayerClf=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_le...      presort=False, random_state=None, splitter='best'),\n",
       "            use_base_prob=False, v_fold=5),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'v_fold': [5], 'baseClfList': [('tree', 'logit', 'tree_bagging'), ('tree_adaboost', 'knn', 'random_forest')], 'multiplyBaseClf': [2], 'stackLayerClf': [DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "    ...r='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)], 'use_base_prob': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf2 = linear_model.LogisticRegression()\n",
    "clf3 = neighbors.KNeighborsClassifier()\n",
    "su =  SuperLearnerClassifier()\n",
    "\n",
    "param_grid = [\n",
    " { \"v_fold\": [5], \"baseClfList\" : [(\"tree\", \"logit\", \"tree_bagging\") , (\"tree_adaboost\", \"knn\" , \"random_forest\")], \\\n",
    "   \"multiplyBaseClf\" : [2] , \\\n",
    "  \"stackLayerClf\" : [clf1, clf2] , \"use_base_prob\" : [True, False] }\n",
    "]\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(su, param_grid, verbose = 2)\n",
    "my_tuned_model.fit(X,Y)  #LM keep it X and Y for 6000 examples as this will be used in task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'baseClfList': ('tree', 'logit', 'tree_bagging'),\n",
       " 'multiplyBaseClf': 2,\n",
       " 'stackLayerClf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'use_base_prob': True,\n",
       " 'v_fold': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_model.best_params_)\n",
    "display(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model selected by the grid search on a hold-out dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> I am using test.csv dataset (10000 examples) as a hold out dataset to evaluate the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8447\n"
     ]
    }
   ],
   "source": [
    "y_hat = my_tuned_model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Impact of Adding Original Descriptive Features at the Stack Layer (Task 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the impact of adding original descriptive features at the stack layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> I've trained two models namely su1 and su2, to evaluate the impact of adding original descriptive features at stack layer. I am evaluating the accuracy and F1 score for those models as data is uniformly distributed using test.csv dataset (10000 examples). From results, adding descriptive features at the stack layer improved the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without adding original descriptive features --> Accuracy is :  0.85  F1 score is :  0.85\n",
      "adding original descriptive features         --> Accuracy is :  0.85  F1 score is :  0.85\n"
     ]
    }
   ],
   "source": [
    "clf= linear_model.LogisticRegression()\n",
    "su1 =  SuperLearnerClassifier(v_fold=5, baseClfList=['tree_adaboost', 'knn', 'random_forest'], stackLayerClf=clf,\\\n",
    "                             multiplyBaseClf = 2, use_base_prob=True, add_ip_features_stackLayer=False)\n",
    "su1.fit(X, Y)\n",
    "\n",
    "su2 =  SuperLearnerClassifier(v_fold=5, baseClfList=['tree_adaboost', 'knn', 'random_forest'], stackLayerClf=clf,\\\n",
    "                              multiplyBaseClf = 2, use_base_prob=True, add_ip_features_stackLayer=True)\n",
    "su2.fit(X, Y)\n",
    "\n",
    "y_hat = su1.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"Without adding original descriptive features --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))\n",
    "\n",
    "y_hat = su2.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, y_hat) \n",
    "f1_score = metrics.f1_score(Y_test,y_hat, average = \"macro\")\n",
    "print(\"adding original descriptive features         --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , round(f1_score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note </b>Due to lack of computational power I am using the 1/10th dataset from train.csv to calculate the cross value with 10 fold. This might give us less score than above cell because of the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : [0.765625   0.67741935 0.74193548 0.64516129 0.78688525 0.66666667\n",
      " 0.63793103 0.68965517 0.71929825 0.80357143]\n",
      "F1 measure : [0.78588162 0.61256688 0.76994505 0.6497513  0.7724026  0.70611111\n",
      " 0.69316184 0.68514153 0.66554568 0.80756133]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(su, X_cross, Y_cross, cv=10 )  \n",
    "print(\"Accuracy :\", scores)\n",
    "scores = cross_val_score(su, X_cross, Y_cross, cv=10 , scoring='f1_macro')  \n",
    "print(\"F1 measure :\", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Ensemble Model (Task 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an analysis to investigate the strength of the base estimators and the strengths of the correlations between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> Note:</b> While calculating the correlation between the base estimators we should not take into account the difference between ranks of the labels. As in Kendall, the relative position of labels is more important that difference between them so I'm using the Kendall for calculating the correlation between the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "su_corr = SuperLearnerClassifier(baseClfList=[\"tree\" , \"logit\" , \"random_forest\" , \"tree_bagging\" , \"tree_adaboost\" , \"knn\" , \"nn\"], \\\n",
    "                                stackLayerClf = clf, multiplyBaseClf=1, use_base_prob=True, add_ip_features_stackLayer = True)\n",
    "su_corr.fit(X,Y)\n",
    "\n",
    "sup_learner = su_corr.predict(X_test)\n",
    "tree = su_corr.tree_model.predict(X_test)\n",
    "logit = su_corr.logit_model.predict(X_test)\n",
    "random_forest = su_corr.random_forest_model.predict(X_test)\n",
    "tree_bagging = su_corr.tree_bagging_model.predict(X_test)\n",
    "tree_adaboost = su_corr.tree_adaboost_model.predict(X_test)\n",
    "knn = su_corr.knn_model.predict(X_test)\n",
    "nn = su_corr.nn_model.predict(X_test)\n",
    "ydf = pd.DataFrame()\n",
    "ydf[\"label\"] = Y_test\n",
    "ydf[\"sup_learner\"] = sup_learner\n",
    "ydf[\"tree\"] = tree\n",
    "ydf[\"logit\"] = logit\n",
    "ydf[\"random_forest\"] = random_forest\n",
    "ydf[\"tree_bagging\"] = tree_bagging\n",
    "ydf[\"tree_adaboost\"] = tree_adaboost\n",
    "ydf[\"knn\"] = knn\n",
    "ydf[\"nn\"] = nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: </b> We can see each base estimators is strong predictors in their own domain except the tree_adaboost and tree_bagging as they bring the more diversity in our Super Learner. Accuracy of each estimator is considerably high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super learner  --> Accuracy is :  0.8  F1 score is :  0.8014755612300686\n",
      "Tree model     --> Accuracy is :  0.75  F1 score is :  0.7490904612027914\n",
      "Logistic model --> Accuracy is :  0.84  F1 score is :  0.8370865628655426\n",
      "Random Forest  --> Accuracy is :  0.84  F1 score is :  0.8347836913312395\n",
      "Tree baggaing  --> Accuracy is :  0.79  F1 score is :  0.7882661377711778\n",
      "Tree adaboost  --> Accuracy is :  0.62  F1 score is :  0.6245726152721135\n",
      "Knn            --> Accuracy is :  0.82  F1 score is :  0.8146768051321706\n",
      "Neural network --> Accuracy is :  0.86  F1 score is :  0.8557464421556205\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(Y_test, sup_learner) \n",
    "f1_score = metrics.f1_score(Y_test,sup_learner, average = \"macro\")\n",
    "print(\"Super learner  --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, tree) \n",
    "f1_score = metrics.f1_score(Y_test, tree, average = \"macro\")\n",
    "print(\"Tree model     --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, logit) \n",
    "f1_score = metrics.f1_score(Y_test, logit, average = \"macro\")\n",
    "print(\"Logistic model --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, random_forest) \n",
    "f1_score = metrics.f1_score(Y_test, random_forest, average = \"macro\")\n",
    "print(\"Random Forest  --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, tree_bagging) \n",
    "f1_score = metrics.f1_score(Y_test, tree_bagging, average = \"macro\")\n",
    "print(\"Tree baggaing  --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, tree_adaboost) \n",
    "f1_score = metrics.f1_score(Y_test, tree_adaboost, average = \"macro\")\n",
    "print(\"Tree adaboost  --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, knn) \n",
    "f1_score = metrics.f1_score(Y_test, knn, average = \"macro\")\n",
    "print(\"Knn            --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y_test, nn) \n",
    "f1_score = metrics.f1_score(Y_test, nn, average = \"macro\")\n",
    "print(\"Neural network --> Accuracy is : \" , round(accuracy,2) , \" F1 score is : \" , f1_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27853bc4390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAI+CAYAAAAFJobkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSQ/x/HEL4Rig6xOwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2780137aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = ydf.corr(method='kendall')\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values , annot_kws={\"size\": 16}, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> Heatmap interpret the correlation between estimators and Super learner nicely. Lable is the ground truth for examples in heatmap.\n",
    "Each cell in a row has an almost different gradient. That is simply interpreting that models are weakly correlated with each other. Weakly co-related models shown in blue gradient and highly correlated models shown in reddish gradient.\n",
    "Less correlated models have high diversity and vice versa. \n",
    "For the heatmap, I have also compared 7 base estimators with Super Learner and actual ground truth. In overall, estimators show good diversity among each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col0 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col1 {\n",
       "            \n",
       "                background-color:  #cdd9ec;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col2 {\n",
       "            \n",
       "                background-color:  #a9c6fd;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col3 {\n",
       "            \n",
       "                background-color:  #e7d7ce;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col4 {\n",
       "            \n",
       "                background-color:  #e5d8d1;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col5 {\n",
       "            \n",
       "                background-color:  #ccd9ed;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col7 {\n",
       "            \n",
       "                background-color:  #dbdcde;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col8 {\n",
       "            \n",
       "                background-color:  #f0cdbb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col0 {\n",
       "            \n",
       "                background-color:  #cedaeb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col1 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col2 {\n",
       "            \n",
       "                background-color:  #a3c2fe;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col3 {\n",
       "            \n",
       "                background-color:  #dedcdb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col4 {\n",
       "            \n",
       "                background-color:  #e9d5cb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col5 {\n",
       "            \n",
       "                background-color:  #d4dbe6;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col7 {\n",
       "            \n",
       "                background-color:  #d6dce4;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col8 {\n",
       "            \n",
       "                background-color:  #e7d7ce;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col0 {\n",
       "            \n",
       "                background-color:  #b7cff9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col1 {\n",
       "            \n",
       "                background-color:  #afcafc;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col2 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col3 {\n",
       "            \n",
       "                background-color:  #c1d4f4;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col4 {\n",
       "            \n",
       "                background-color:  #d5dbe5;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col5 {\n",
       "            \n",
       "                background-color:  #cedaeb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col7 {\n",
       "            \n",
       "                background-color:  #c6d6f1;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col8 {\n",
       "            \n",
       "                background-color:  #c5d6f2;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col0 {\n",
       "            \n",
       "                background-color:  #e6d7cf;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col1 {\n",
       "            \n",
       "                background-color:  #dbdcde;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col2 {\n",
       "            \n",
       "                background-color:  #b2ccfb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col3 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col4 {\n",
       "            \n",
       "                background-color:  #f5c0a7;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col5 {\n",
       "            \n",
       "                background-color:  #ead4c8;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col7 {\n",
       "            \n",
       "                background-color:  #efcfbf;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col8 {\n",
       "            \n",
       "                background-color:  #f7a889;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col0 {\n",
       "            \n",
       "                background-color:  #dfdbd9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col1 {\n",
       "            \n",
       "                background-color:  #e2dad5;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col2 {\n",
       "            \n",
       "                background-color:  #c3d5f4;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col3 {\n",
       "            \n",
       "                background-color:  #f4c5ad;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col4 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col5 {\n",
       "            \n",
       "                background-color:  #f7aa8c;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col7 {\n",
       "            \n",
       "                background-color:  #f7b89c;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col8 {\n",
       "            \n",
       "                background-color:  #f5c2aa;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col0 {\n",
       "            \n",
       "                background-color:  #cad8ef;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col1 {\n",
       "            \n",
       "                background-color:  #cfdaea;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col2 {\n",
       "            \n",
       "                background-color:  #c0d4f5;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col3 {\n",
       "            \n",
       "                background-color:  #ead5c9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col4 {\n",
       "            \n",
       "                background-color:  #f7a889;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col5 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col7 {\n",
       "            \n",
       "                background-color:  #edd1c2;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col8 {\n",
       "            \n",
       "                background-color:  #e6d7cf;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col0 {\n",
       "            \n",
       "                background-color:  #4c66d6;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col1 {\n",
       "            \n",
       "                background-color:  #4a63d3;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col2 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col3 {\n",
       "            \n",
       "                background-color:  #4f69d9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col4 {\n",
       "            \n",
       "                background-color:  #5a78e4;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col5 {\n",
       "            \n",
       "                background-color:  #516ddb;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col6 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col7 {\n",
       "            \n",
       "                background-color:  #4f69d9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col8 {\n",
       "            \n",
       "                background-color:  #536edd;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col0 {\n",
       "            \n",
       "                background-color:  #dadce0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col1 {\n",
       "            \n",
       "                background-color:  #d4dbe6;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col2 {\n",
       "            \n",
       "                background-color:  #b9d0f9;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col3 {\n",
       "            \n",
       "                background-color:  #efcebd;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col4 {\n",
       "            \n",
       "                background-color:  #f7b497;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col5 {\n",
       "            \n",
       "                background-color:  #eed0c0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col7 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col8 {\n",
       "            \n",
       "                background-color:  #f2cbb7;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col0 {\n",
       "            \n",
       "                background-color:  #eed0c0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col1 {\n",
       "            \n",
       "                background-color:  #e4d9d2;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col2 {\n",
       "            \n",
       "                background-color:  #b5cdfa;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col3 {\n",
       "            \n",
       "                background-color:  #f7a98b;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col4 {\n",
       "            \n",
       "                background-color:  #f5c0a7;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col5 {\n",
       "            \n",
       "                background-color:  #e5d8d1;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col6 {\n",
       "            \n",
       "                background-color:  #3b4cc0;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col7 {\n",
       "            \n",
       "                background-color:  #f1ccb8;\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col8 {\n",
       "            \n",
       "                background-color:  #b40426;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th class=\"blank level0\" >\n",
       "                  \n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col0\" colspan=1>\n",
       "                  label\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col1\" colspan=1>\n",
       "                  sup_learner\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col2\" colspan=1>\n",
       "                  tree\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col3\" colspan=1>\n",
       "                  logit\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col4\" colspan=1>\n",
       "                  random_forest\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col5\" colspan=1>\n",
       "                  tree_bagging\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col6\" colspan=1>\n",
       "                  tree_adaboost\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col7\" colspan=1>\n",
       "                  knn\n",
       "                \n",
       "                \n",
       "                \n",
       "                <th class=\"col_heading level0 col8\" colspan=1>\n",
       "                  nn\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row0\" rowspan=1>\n",
       "                    label\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col0\"\n",
       "                 class=\"data row0 col0\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col1\"\n",
       "                 class=\"data row0 col1\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col2\"\n",
       "                 class=\"data row0 col2\" >\n",
       "                    0.73\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col3\"\n",
       "                 class=\"data row0 col3\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col4\"\n",
       "                 class=\"data row0 col4\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col5\"\n",
       "                 class=\"data row0 col5\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col6\"\n",
       "                 class=\"data row0 col6\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col7\"\n",
       "                 class=\"data row0 col7\" >\n",
       "                    0.79\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row0_col8\"\n",
       "                 class=\"data row0 col8\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row1\" rowspan=1>\n",
       "                    sup_learner\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col0\"\n",
       "                 class=\"data row1 col0\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col1\"\n",
       "                 class=\"data row1 col1\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col2\"\n",
       "                 class=\"data row1 col2\" >\n",
       "                    0.72\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col3\"\n",
       "                 class=\"data row1 col3\" >\n",
       "                    0.79\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col4\"\n",
       "                 class=\"data row1 col4\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col5\"\n",
       "                 class=\"data row1 col5\" >\n",
       "                    0.78\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col6\"\n",
       "                 class=\"data row1 col6\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col7\"\n",
       "                 class=\"data row1 col7\" >\n",
       "                    0.78\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row1_col8\"\n",
       "                 class=\"data row1 col8\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row2\" rowspan=1>\n",
       "                    tree\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col0\"\n",
       "                 class=\"data row2 col0\" >\n",
       "                    0.73\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col1\"\n",
       "                 class=\"data row2 col1\" >\n",
       "                    0.72\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col2\"\n",
       "                 class=\"data row2 col2\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col3\"\n",
       "                 class=\"data row2 col3\" >\n",
       "                    0.74\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col4\"\n",
       "                 class=\"data row2 col4\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col5\"\n",
       "                 class=\"data row2 col5\" >\n",
       "                    0.76\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col6\"\n",
       "                 class=\"data row2 col6\" >\n",
       "                    0.56\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col7\"\n",
       "                 class=\"data row2 col7\" >\n",
       "                    0.75\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row2_col8\"\n",
       "                 class=\"data row2 col8\" >\n",
       "                    0.74\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row3\" rowspan=1>\n",
       "                    logit\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col0\"\n",
       "                 class=\"data row3 col0\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col1\"\n",
       "                 class=\"data row3 col1\" >\n",
       "                    0.79\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col2\"\n",
       "                 class=\"data row3 col2\" >\n",
       "                    0.74\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col3\"\n",
       "                 class=\"data row3 col3\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col4\"\n",
       "                 class=\"data row3 col4\" >\n",
       "                    0.85\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col5\"\n",
       "                 class=\"data row3 col5\" >\n",
       "                    0.82\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col6\"\n",
       "                 class=\"data row3 col6\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col7\"\n",
       "                 class=\"data row3 col7\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row3_col8\"\n",
       "                 class=\"data row3 col8\" >\n",
       "                    0.88\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row4\" rowspan=1>\n",
       "                    random_forest\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col0\"\n",
       "                 class=\"data row4 col0\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col1\"\n",
       "                 class=\"data row4 col1\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col2\"\n",
       "                 class=\"data row4 col2\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col3\"\n",
       "                 class=\"data row4 col3\" >\n",
       "                    0.85\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col4\"\n",
       "                 class=\"data row4 col4\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col5\"\n",
       "                 class=\"data row4 col5\" >\n",
       "                    0.88\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col6\"\n",
       "                 class=\"data row4 col6\" >\n",
       "                    0.61\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col7\"\n",
       "                 class=\"data row4 col7\" >\n",
       "                    0.87\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row4_col8\"\n",
       "                 class=\"data row4 col8\" >\n",
       "                    0.86\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row5\" rowspan=1>\n",
       "                    tree_bagging\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col0\"\n",
       "                 class=\"data row5 col0\" >\n",
       "                    0.77\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col1\"\n",
       "                 class=\"data row5 col1\" >\n",
       "                    0.78\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col2\"\n",
       "                 class=\"data row5 col2\" >\n",
       "                    0.76\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col3\"\n",
       "                 class=\"data row5 col3\" >\n",
       "                    0.82\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col4\"\n",
       "                 class=\"data row5 col4\" >\n",
       "                    0.88\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col5\"\n",
       "                 class=\"data row5 col5\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col6\"\n",
       "                 class=\"data row5 col6\" >\n",
       "                    0.6\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col7\"\n",
       "                 class=\"data row5 col7\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row5_col8\"\n",
       "                 class=\"data row5 col8\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row6\" rowspan=1>\n",
       "                    tree_adaboost\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col0\"\n",
       "                 class=\"data row6 col0\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col1\"\n",
       "                 class=\"data row6 col1\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col2\"\n",
       "                 class=\"data row6 col2\" >\n",
       "                    0.56\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col3\"\n",
       "                 class=\"data row6 col3\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col4\"\n",
       "                 class=\"data row6 col4\" >\n",
       "                    0.61\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col5\"\n",
       "                 class=\"data row6 col5\" >\n",
       "                    0.6\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col6\"\n",
       "                 class=\"data row6 col6\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col7\"\n",
       "                 class=\"data row6 col7\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row6_col8\"\n",
       "                 class=\"data row6 col8\" >\n",
       "                    0.6\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row7\" rowspan=1>\n",
       "                    knn\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col0\"\n",
       "                 class=\"data row7 col0\" >\n",
       "                    0.79\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col1\"\n",
       "                 class=\"data row7 col1\" >\n",
       "                    0.78\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col2\"\n",
       "                 class=\"data row7 col2\" >\n",
       "                    0.75\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col3\"\n",
       "                 class=\"data row7 col3\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col4\"\n",
       "                 class=\"data row7 col4\" >\n",
       "                    0.87\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col5\"\n",
       "                 class=\"data row7 col5\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col6\"\n",
       "                 class=\"data row7 col6\" >\n",
       "                    0.59\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col7\"\n",
       "                 class=\"data row7 col7\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row7_col8\"\n",
       "                 class=\"data row7 col8\" >\n",
       "                    0.84\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                \n",
       "                <th id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491\"\n",
       "                 class=\"row_heading level0 row8\" rowspan=1>\n",
       "                    nn\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col0\"\n",
       "                 class=\"data row8 col0\" >\n",
       "                    0.83\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col1\"\n",
       "                 class=\"data row8 col1\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col2\"\n",
       "                 class=\"data row8 col2\" >\n",
       "                    0.74\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col3\"\n",
       "                 class=\"data row8 col3\" >\n",
       "                    0.88\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col4\"\n",
       "                 class=\"data row8 col4\" >\n",
       "                    0.86\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col5\"\n",
       "                 class=\"data row8 col5\" >\n",
       "                    0.81\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col6\"\n",
       "                 class=\"data row8 col6\" >\n",
       "                    0.6\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col7\"\n",
       "                 class=\"data row8 col7\" >\n",
       "                    0.84\n",
       "                \n",
       "                \n",
       "                \n",
       "                <td id=\"T_56b1f154_2491_11e8_8dd5_f430b98e2491row8_col8\"\n",
       "                 class=\"data row8 col8\" >\n",
       "                    1.0\n",
       "                \n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x27800c9b240>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.corr(method='kendall').style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)\n",
    "#plasma inferno magma viridis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to run entire note book is 120.30 minutes\n"
     ]
    }
   ],
   "source": [
    "tocks = time.time()\n",
    "mins = (tocks-ticks) / 60\n",
    "print(\"time taken to run entire note book is {0:.2f} minutes\".format(mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
